{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f2a27b7",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04b6f02",
   "metadata": {},
   "source": [
    "### Data Loading and Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2c9cc776",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Martin\\AppData\\Local\\Temp\\ipykernel_7148\\694377699.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  games_1996.loc[:, 'game_year'] = games_1996['game_date'].dt.year\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV files\n",
    "attendance = pd.read_csv('PublicData/game_info.csv') #contains the attendancce column\n",
    "games = pd.read_csv('PublicData/game.csv') #contains game information (which teams, who won, etc.)\n",
    "stadion_capacities = pd.read_csv('CreatedData/stadion_capacity.csv') #contains stadium capacities and when the stadium was used\n",
    "\n",
    "# Merge attendance and games on game_id\n",
    "games = pd.merge(attendance, games, on='game_id', how='inner')\n",
    "\n",
    "games.drop(columns=['game_date_y'], inplace=True) # drop second game date\n",
    "games.rename(columns={'game_date_x': 'game_date'}, inplace=True) \n",
    "games['game_date'] = pd.to_datetime(games['game_date'])\n",
    "\n",
    "# Filter for games from 1996-97 season onwards\n",
    "# NBA season starts in October, so keep games from October 1996 onwards\n",
    "games_1996 = games[\n",
    "    ((games['game_date'].dt.year == 1996) & (games['game_date'].dt.month >= 10)) |\n",
    "    (games['game_date'].dt.year > 1996)\n",
    "]\n",
    "\n",
    "# Add a year column\n",
    "games_1996.loc[:, 'game_year'] = games_1996['game_date'].dt.year\n",
    "\n",
    "# Save to CSV\n",
    "# games_1996.to_csv('nba_games_since_1996.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d3a08649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to determine if a game is in first or second half of season\n",
    "def get_season_half(date):\n",
    "    # NBA season typically starts in October and ends in April\n",
    "    # If month is October through December, it's first half\n",
    "    # If month is January through June, it's second half\n",
    "    if date.month >= 10:\n",
    "        return 'First Half'\n",
    "    else:\n",
    "        return 'Second Half'\n",
    "\n",
    "# Function to match game with correct arena capacity\n",
    "def get_arena_capacity(row, stadiums_df):\n",
    "    game_date = row['game_date']\n",
    "    team_id = row['team_id_home']\n",
    "    \n",
    "    # Get all stadiums for this team\n",
    "    team_stadiums = stadiums_df[stadiums_df['team_id'] == team_id]\n",
    "    \n",
    "    # Find the correct stadium based on date\n",
    "    for _, stadium in team_stadiums.iterrows():\n",
    "        start_year = stadium['start_year']\n",
    "        end_year = stadium['end_year']\n",
    "        \n",
    "        # Handle the mid-year season transition\n",
    "        if game_date.month >= 10:\n",
    "            game_year = game_date.year + 1\n",
    "        else:\n",
    "            game_year = game_date.year\n",
    "            \n",
    "        if start_year <= game_year <= end_year:\n",
    "            return stadium['capacity']\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "aec59fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Martin\\AppData\\Local\\Temp\\ipykernel_7148\\2324553091.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  games_1996.loc[:, 'season_half'] = games_1996['game_date'].apply(get_season_half)\n",
      "C:\\Users\\Martin\\AppData\\Local\\Temp\\ipykernel_7148\\2324553091.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  games_1996.loc[:, 'arena_capacity'] = games_1996.apply(lambda x: get_arena_capacity(x, stadion_capacities), axis=1)\n",
      "C:\\Users\\Martin\\AppData\\Local\\Temp\\ipykernel_7148\\2324553091.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  games_1996.loc[:, 'occupancy_rate'] = (games_1996['attendance'] / games_1996['arena_capacity']) * 100\n"
     ]
    }
   ],
   "source": [
    "# Add season half (First or Second Half)\n",
    "games_1996.loc[:, 'season_half'] = games_1996['game_date'].apply(get_season_half)\n",
    "\n",
    "# Get arena capacity for each game\n",
    "games_1996.loc[:, 'arena_capacity'] = games_1996.apply(lambda x: get_arena_capacity(x, stadion_capacities), axis=1)\n",
    "\n",
    "# Calculate occupancy rate\n",
    "games_1996.loc[:, 'occupancy_rate'] = (games_1996['attendance'] / games_1996['arena_capacity']) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0762765f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move \"arena_capacity\" and \"occupancy_rate\" right after \"attendance\" and disregard columns like fg % -> shorten the dataframe\n",
    "new_order = [\n",
    "    \"game_id\", \"game_date\", \"attendance\", \n",
    "    \"arena_capacity\", \"occupancy_rate\", \n",
    "    \"game_time\", \"game_year\", \"season_id\",\n",
    "    \"team_id_home\", \"team_abbreviation_home\", \"matchup_home\", \"wl_home\",\n",
    "    \"team_id_away\", \"team_abbreviation_away\",\n",
    "    \"season_type\", \"season_half\"\n",
    "]\n",
    "\n",
    "master_short_data = games_1996[new_order]\n",
    "master_short_data.to_csv('Master_Short_Data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7046c204",
   "metadata": {},
   "source": [
    "### Filtering and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "90a4e9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Martin\\AppData\\Local\\Temp\\ipykernel_7148\\2081288120.py:11: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['game_hour'] = pd.to_datetime(df['game_time'], errors='coerce').dt.hour\n"
     ]
    }
   ],
   "source": [
    "Master = master_short_data\n",
    "\n",
    "# Daten laden\n",
    "df = pd.read_csv('Master_Short_Data.csv')\n",
    "df['game_date'] = pd.to_datetime(df['game_date'])\n",
    "\n",
    "# Extract date-based features\n",
    "df['game_year'] = df['game_date'].dt.year\n",
    "df['game_month'] = df['game_date'].dt.month\n",
    "df['game_dayofweek'] = df['game_date'].dt.dayofweek  # Monday=0, Sunday=6\n",
    "df['game_hour'] = pd.to_datetime(df['game_time'], errors='coerce').dt.hour\n",
    "\n",
    "\n",
    "df = df.dropna(subset=['arena_capacity'])\n",
    "df = df.dropna(subset=['attendance'])\n",
    "\n",
    "# Liste aller Teams, die mindestens einmal als Heimteam vorkommen\n",
    "home_teams = df['team_abbreviation_home'].unique()\n",
    "\n",
    "# Nur Einträge behalten, bei denen das Auswärtsteam auch in den Heimteams vorkommt\n",
    "df = df[df['team_abbreviation_away'].isin(home_teams)]\n",
    "\n",
    "df.to_csv('Master_Short_Data.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "60fbd8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Master_Short_Data.csv')\n",
    "\n",
    "# drop all rows between 2020 march and 2021 september\n",
    "df = df[(df['game_date'] < '2020-03-01') | (df['game_date'] > '2021-10-15')]\n",
    "\n",
    "df.to_csv('Master_Short_Data.csv', index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afba303",
   "metadata": {},
   "source": [
    "### Adding New Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1227ca",
   "metadata": {},
   "source": [
    "### Adding Records of Games to Master Short "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "df5464d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_team_records(df):\n",
    "    # Create copy to avoid modifying original\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Sort by season and date to ensure correct order\n",
    "    # df = df.sort_values(['season_id', 'game_date'])\n",
    "    \n",
    "    # Initialize new columns\n",
    "    df['home_wins'] = 0\n",
    "    df['home_losses'] = 0\n",
    "    df['home_win_streak'] = 0\n",
    "    df['away_wins'] = 0\n",
    "    df['away_losses'] = 0\n",
    "    df['away_win_streak'] = 0\n",
    "    \n",
    "    # Dictionary to store team records for each season\n",
    "    # Format: {season_id: {team_id: {'wins': x, 'losses': y, 'streak': z}}}\n",
    "    season_records = {}\n",
    "    \n",
    "    # Process each game\n",
    "    for idx, row in df.iterrows():\n",
    "        season = row['season_id']\n",
    "        home_team = row['team_id_home']\n",
    "        away_team = row['team_id_away']\n",
    "        \n",
    "        # Initialize season records if needed\n",
    "        if season not in season_records:\n",
    "            season_records[season] = {}\n",
    "            \n",
    "        # Get or initialize home team records\n",
    "        if home_team not in season_records[season]:\n",
    "            home_record = {'wins': 0, 'losses': 0, 'streak': 0}\n",
    "        else:\n",
    "            home_record = season_records[season][home_team].copy()\n",
    "            \n",
    "        # Get or initialize away team records\n",
    "        if away_team not in season_records[season]:\n",
    "            away_record = {'wins': 0, 'losses': 0, 'streak': 0}\n",
    "        else:\n",
    "            away_record = season_records[season][away_team].copy()\n",
    "        \n",
    "        # Add result of current game\n",
    "        if row['wl_home'] == 'W':\n",
    "            home_record['wins'] += 1\n",
    "            away_record['losses'] += 1\n",
    "            home_record['streak'] = max(1, home_record['streak'] + 1)\n",
    "            away_record['streak'] = min(-1, away_record['streak'] - 1)\n",
    "        else:\n",
    "            home_record['losses'] += 1\n",
    "            away_record['wins'] += 1\n",
    "            home_record['streak'] = min(-1, home_record['streak'] - 1)\n",
    "            away_record['streak'] = max(1, away_record['streak'] + 1)\n",
    "        \n",
    "        # Store current records including this game\n",
    "        df.at[idx, 'home_wins'] = home_record['wins']\n",
    "        df.at[idx, 'home_losses'] = home_record['losses']\n",
    "        df.at[idx, 'home_win_streak'] = home_record['streak']\n",
    "        df.at[idx, 'away_wins'] = away_record['wins']\n",
    "        df.at[idx, 'away_losses'] = away_record['losses']\n",
    "        df.at[idx, 'away_win_streak'] = away_record['streak']\n",
    "        \n",
    "        # Store updated records for next games\n",
    "        season_records[season][home_team] = home_record\n",
    "        season_records[season][away_team] = away_record\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fcb19d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_team_records(df).to_csv('Master_Short_Data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9f5048",
   "metadata": {},
   "source": [
    "### Adding Rivalries to Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "87ec00f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load Master Short Data and rivalries\n",
    "master_df = pd.read_csv('Master_Short_Data.csv')\n",
    "rivalries_df = pd.read_csv('CreatedData/rivalries.csv')\n",
    "\n",
    "# Prepare set of rivalry pairs (both directions)\n",
    "rival_pairs = set()\n",
    "for _, row in rivalries_df.iterrows():\n",
    "    t1 = row['team_id']\n",
    "    t2 = row['rival_team_id']\n",
    "    rival_pairs.add((t1, t2))\n",
    "    rival_pairs.add((t2, t1))\n",
    "\n",
    "def is_rival_game(row):\n",
    "    return int((row['team_id_home'], row['team_id_away']) in rival_pairs)\n",
    "\n",
    "# Add rival_game column (1 = yes, 0 = no)\n",
    "master_df['rival_game'] = master_df.apply(is_rival_game, axis=1)\n",
    "\n",
    "# Save updated dataframe\n",
    "master_df.to_csv('Master_Short_Data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976312f5",
   "metadata": {},
   "source": [
    "### Adding defending champions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "936a9542",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load champions data if not already loaded\n",
    "champions_df = pd.read_csv('CreatedData/champions.csv')\n",
    "\n",
    "# Function to get defending champion for a given team, year, and season_half\n",
    "def get_defending_champ(team_id, game_year, season_half):\n",
    "    if season_half == 'Second Half':\n",
    "        champ_year = game_year - 1\n",
    "    else:\n",
    "        champ_year = game_year\n",
    "    champ_row = champions_df[champions_df['year'] == champ_year]\n",
    "    if not champ_row.empty and champ_row.iloc[0]['team_id'] == team_id:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "# Add defending champion columns for home and away teams\n",
    "master_df['defending_champ_home'] = master_df.apply(\n",
    "    lambda row: get_defending_champ(row['team_id_home'], row['game_year'], row['season_half']), axis=1\n",
    ")\n",
    "master_df['defending_champ_away'] = master_df.apply(\n",
    "    lambda row: get_defending_champ(row['team_id_away'], row['game_year'], row['season_half']), axis=1\n",
    ")\n",
    "\n",
    "# Save updated dataframe\n",
    "master_df.to_csv('Master_Short_Data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b2143c",
   "metadata": {},
   "source": [
    "### Adding MVPs to Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "37825bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load Master Short Data and MVPs\n",
    "master_df = pd.read_csv('Master_Short_Data.csv')\n",
    "mvps_df = pd.read_csv('CreatedData/mvps.csv')\n",
    "\n",
    "# Prepare MVP mapping for both season splits\n",
    "mvp_map = {}\n",
    "for _, row in mvps_df.iterrows():\n",
    "    mvp_team = row['team_id']\n",
    "    mvp_year = row['year']\n",
    "    # Assign MVP to previous year + Second Half and current year + First Half\n",
    "    mvp_map[(mvp_year - 1, 'Second Half', mvp_team)] = 1\n",
    "    mvp_map[(mvp_year, 'First Half', mvp_team)] = 1\n",
    "\n",
    "def has_mvp(row):\n",
    "    key = (row['game_year'], row['season_half'], row['team_id_home'])\n",
    "    return mvp_map.get(key, 0)\n",
    "\n",
    "# Add MVP column for home team\n",
    "master_df['home_mvp'] = master_df.apply(has_mvp, axis=1)\n",
    "\n",
    "# Add MVP column for away team\n",
    "def has_mvp_away(row):\n",
    "    key = (row['game_year'], row['season_half'], row['team_id_away'])\n",
    "    return mvp_map.get(key, 0)\n",
    "\n",
    "master_df['away_mvp'] = master_df.apply(has_mvp_away, axis=1)\n",
    "\n",
    "# Save updated dataframe\n",
    "master_df.to_csv('Master_Short_Data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264b8068",
   "metadata": {},
   "source": [
    "### Adding attendance of the previous season to Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4568ab9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Ensure game_date is datetime\n",
    "master_df['game_date'] = pd.to_datetime(master_df['game_date'])\n",
    "\n",
    "def get_prev_season_avg(row, df):\n",
    "    team = row['team_id_home']\n",
    "    season = row['game_year']\n",
    "    half = row['season_half']\n",
    "    \n",
    "    if half == 'Second Half':\n",
    "        # Previous season: previous year Second Half + current year First Half\n",
    "        mask = (\n",
    "            ((df['team_id_home'] == team) & \n",
    "             (((df['game_year'] == season - 1) & (df['season_half'] == 'Second Half')) |\n",
    "              ((df['game_year'] == season) & (df['season_half'] == 'First Half'))))\n",
    "        )\n",
    "    else:  # First Half\n",
    "        # Previous season: two years back Second Half + one year back First Half\n",
    "        mask = (\n",
    "            ((df['team_id_home'] == team) & \n",
    "             (((df['game_year'] == season - 2) & (df['season_half'] == 'Second Half')) |\n",
    "              ((df['game_year'] == season - 1) & (df['season_half'] == 'First Half'))))\n",
    "        )\n",
    "    prev_games = df.loc[mask, 'attendance']\n",
    "    if len(prev_games) == 0:\n",
    "        return np.nan\n",
    "    return prev_games.mean()\n",
    "\n",
    "master_df['attendance_prev_season_avg'] = master_df.apply(lambda row: get_prev_season_avg(row, master_df), axis=1)\n",
    "\n",
    "# Save to CSV\n",
    "master_df.to_csv('Master_Short_Data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06cba65",
   "metadata": {},
   "source": [
    "### Adding laged attendance (two games) to Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b4bec538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add lag features for attendance (previous 1 and 2 games for each home team)\n",
    "df = pd.read_csv('Master_Short_Data.csv')\n",
    "df = df.sort_values(['team_id_home', 'game_date'])\n",
    "\n",
    "df['attendance_lag1'] = df.groupby('team_id_home')['attendance'].shift(1)\n",
    "df['attendance_lag2'] = df.groupby('team_id_home')['attendance'].shift(2)\n",
    "\n",
    "\n",
    "df = df.sort_values(['game_date'])\n",
    "\n",
    "df.to_csv('Master_Short_Data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
